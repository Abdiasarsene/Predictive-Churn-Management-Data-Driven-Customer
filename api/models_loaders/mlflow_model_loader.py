# server_layer/events/mlflow_model_loader.py
import os
import mlflow
import logging
from api.utils.config import settings

# ====== LOGGING ======
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

class MLflowModelLoader:
    """
    Classe pour charger un mod√®le MLflow depuis un bucket MinIO d√©j√† valid√©.
    La connexion MinIO doit avoir √©t√© valid√©e par MinIOConnectionChecker.
    """

    def __init__(self, experiment_name: str):
        # === Configuration MinIO pour MLflow ===
        # endpoint = (
        #     settings.mlflow_s3_endpoint_uri
        #     if settings.mlflow_s3_endpoint_uri.startswith("http")
        #     else f"http://{settings.mlflow_s3_endpoint_uri}"
        # )

        os.environ["MLFLOW_S3_ENDPOINT_URL"] =settings.mlflow_s3_endpoint_uri
        os.environ["AWS_ACCESS_KEY_ID"] = settings.minio_access_key
        os.environ["AWS_SECRET_ACCESS_KEY"] = settings.minio_secret_key

        # === Connexion MLflow ===
        mlflow.set_tracking_uri(settings.tracking_uri)
        self.experiment = mlflow.get_experiment_by_name(experiment_name)

        if not self.experiment:
            raise ValueError(f"‚ùå Experiment '{experiment_name}' not found in MLflow.")

        self.experiment_id = self.experiment.experiment_id
        logger.info(f"‚úÖ MLflow connected (experiment: {experiment_name})")

    def get_model_uri_by_name(self, model_run_name: str, artifact_path: str = "model") -> str:
        """Retourne l'URI MLflow pour un run donn√©."""
        try:
            runs_df = mlflow.search_runs(experiment_ids=[self.experiment_id])
            matches = runs_df[runs_df["tags.mlflow.runName"] == model_run_name]

            if matches.empty:
                raise ValueError(
                    f"No model found with run name '{model_run_name}' "
                    f"in experiment '{self.experiment.name}'."
                )

            # Prend le run le plus r√©cent si plusieurs
            run_id = matches.iloc[0].run_id
            model_uri = f"runs:/{run_id}/{artifact_path}"
            logger.info(f"‚úÖ Model '{model_run_name}' found ‚Äî URI: {model_uri}")
            return model_uri

        except Exception as e:
            logger.error(f"‚ùå Error searching model '{model_run_name}': {str(e)}", exc_info=True)
            return None

    def load_model_by_name(self, model_run_name: str):
        """Charge le mod√®le depuis MLflow et retourne l'objet Python."""
        try:
            model_uri = self.get_model_uri_by_name(model_run_name)
            if not model_uri:
                raise ValueError(f"Unable to resolve model URI for '{model_run_name}'")

            model = mlflow.sklearn.load_model(model_uri)
            logger.info(f"üì¶ Model '{model_run_name}' successfully loaded from {model_uri}")
            return model

        except Exception as e:
            logger.error(f"‚ùå Error loading model '{model_run_name}': {str(e)}", exc_info=True)
            return None